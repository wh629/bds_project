{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Yelp Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "local = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business json attributes:  ['address', 'attributes', 'business_id', 'categories', 'city', 'hours', 'is_open', 'latitude', 'longitude', 'name', 'postal_code', 'review_count', 'stars', 'state']\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-500b82b64496>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# print(\"photo json attributes: \", list(ph_df.columns.values))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mrev_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreview_fname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"review json attributes: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrev_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\json\\json.py\u001b[0m in \u001b[0;36mread_json\u001b[1;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression)\u001b[0m\n\u001b[0;32m    425\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshould_close\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\json\\json.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    532\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m             obj = self._get_object_parser(\n\u001b[1;32m--> 534\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_combine_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    535\u001b[0m             )\n\u001b[0;32m    536\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\json\\json.py\u001b[0m in \u001b[0;36m_combine_lines\u001b[1;34m(self, lines)\u001b[0m\n\u001b[0;32m    520\u001b[0m         \"\"\"\n\u001b[0;32m    521\u001b[0m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 522\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m'['\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m','\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m']'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    523\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_path = r\"C:\\Users\\Willi\\Documents\\NYU\\2020 Spring\\Big Data Science\\Project\\yelp_dataset/yelp_academic_dataset_\"\n",
    "\n",
    "business_fname = data_path + 'business.json'\n",
    "# checkin_fname = data_path + 'checkin.json'\n",
    "# photo_fname = data_path + 'photo.json'\n",
    "if local:\n",
    "    review_fname = data_path + 'review_short.json'\n",
    "else:\n",
    "    review_fname = data_path + 'review.json'\n",
    "# tip_fname = data_path + 'tip.json'\n",
    "# user_fname = data_path + 'user.json'\n",
    "\n",
    "biz_df = pd.read_json(business_fname, lines=True)\n",
    "print(\"business json attributes: \", list(biz_df.columns.values))\n",
    "\n",
    "# ci_df = pd.read_json(checkin_fname, lines=True)\n",
    "# print(\"checkin json attributes: \", list(ci_df.columns.values))\n",
    "\n",
    "# ph_df = pd.read_json(photo_fname, lines=True)\n",
    "# print(\"photo json attributes: \", list(ph_df.columns.values))\n",
    "\n",
    "rev_df = pd.read_json(review_fname, lines=True)\n",
    "print(\"review json attributes: \", list(rev_df.columns.values))\n",
    "\n",
    "# tip_df = pd.read_json(tip_fname, lines=True)\n",
    "# print(\"tip json attributes: \", list(tip_df.columns.values))\n",
    "\n",
    "# use_df = pd.read_json(user_fname, lines=True)\n",
    "# print(\"user json attributes: \", list(use_df.columns.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Number of Empty Entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"business empty entries: \", biz_df.isna().sum(axis=0))\n",
    "print(\"review empty entries: \", rev_df.isna().sum(axis=0))\n",
    "\n",
    "# print(\"checkin empty entries: \", ci_df.isna().sum(axis=0))\n",
    "# print(\"photo empty entries: \", ph_df.isna().sum(axis=0))\n",
    "# print(\"tip empty entries: \", tip_df.isna().sum(axis=0))\n",
    "# print(\"user empty entries: \", use_df.isna().sum(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"business size: \", biz_df.shape)\n",
    "print(\"review size: \", rev_df.shape)\n",
    "\n",
    "# print(\"checkin size: \", ci_df.shape)\n",
    "# print(\"photo size: \", ph_df.shape)\n",
    "\n",
    "# print(\"tip size: \", tip_df.shape)\n",
    "# print(\"user size: \", use_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set If Restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biz_df['is_restaurant'] = (biz_df.loc[:,'categories'].where(biz_df.loc[:,'categories']\\\n",
    "                                                                 .str.contains('Restaurant')).isna()==False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(biz_df.loc[biz_df.loc[:,'is_restaurant']==False,'categories'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biz_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotDict(valuesDict, topK, fileName, title):\n",
    "    labels = list(valuesDict.keys())[0:topK]\n",
    "    values = list(valuesDict.values())[0:topK]\n",
    "\n",
    "    fig, axes = plt.subplots(figsize=(12, 10))\n",
    "    axes.pie(values,\n",
    "            labels = labels,\n",
    "            \n",
    "            startangle=90)\n",
    "#     plt.figsize=(20, 20)\n",
    "    \n",
    "    plt.title(title)\n",
    "\n",
    "    axes.axis('equal')\n",
    "    plt.savefig(fileName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoryCount = {}\n",
    "\n",
    "for businessCategories in biz_df.categories:\n",
    "    if businessCategories is None:\n",
    "        continue\n",
    "    for category in businessCategories.split(','):\n",
    "        category = category.strip().lower()\n",
    "        if category in categoryCount:\n",
    "            categoryCount[category] = categoryCount[category] + 1\n",
    "        else:\n",
    "            categoryCount[category] = 1\n",
    "            \n",
    "print (\"Total Number of Categories : \" + str(len(categoryCount)))\n",
    "print (\"Total Number of Businesses : \" + str(biz_df.shape[0]))\n",
    "sortedCategoryCountsDict = collections.OrderedDict({k: v for k, v in sorted(categoryCount.items(), key=lambda item: item[1], reverse = True)})\n",
    "plotDict(sortedCategoryCountsDict, 10, \"top10_business_categories.png\", \"Top-10 Business categories\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Reviewed Business Categories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateCount(businessCategories, categoryCount, count):\n",
    "    if businessCategories is None:\n",
    "        return\n",
    "    if review_count == 0:\n",
    "        return\n",
    "    for category in businessCategories.split(','):\n",
    "        category = category.strip().lower()\n",
    "        if category in categoryCount:\n",
    "            categoryCount[category] = categoryCount[category] + count\n",
    "        else:\n",
    "            categoryCount[category] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Cross check this data against review count from business.json.\n",
    "\n",
    "# categoryToReviewCount = {}\n",
    "# for businessId, count in rev_df['business_id'].value_counts().iteritems():\n",
    "\n",
    "#     for categories in biz_df.loc[biz_df['business_id'] == businessId]['categories']:\n",
    "#         if categories is None:\n",
    "#             continue\n",
    "#         for category in categories.split(\",\"):\n",
    "#             if category is None:\n",
    "#                 continue\n",
    "#             category = category.strip().lower()\n",
    "#             if category in categoryToReviewCount:\n",
    "#                 categoryToReviewCount[category]  = categoryToReviewCount[category] + count\n",
    "#             else:\n",
    "#                 categoryToReviewCount[category] = count\n",
    "# sortedcategoryToReviewCount = collections.OrderedDict(\n",
    "#     {k: v for k, v in sorted(categoryToReviewCount.items(), key=lambda item: item[1], reverse = True)})\n",
    "\n",
    "# plotDict(sortedcategoryToReviewCount, 10, \n",
    "#          \"top10_business_by_reviews_categories.png\", \"Top-10 most reviewed business categories\\n\")\n",
    "\n",
    "\n",
    "categoryReviewCounting = {}\n",
    "\n",
    "for i in range (0, biz_df.shape[0]):\n",
    "    row = biz_df.iloc[i]\n",
    "    updateCount(row['categories'], categoryReviewCounting , row['review_count'])\n",
    "\n",
    "sortedcategoryToReviewCount = collections.OrderedDict(\n",
    "    {k: v for k, v in sorted(categoryReviewCounting.items(), key=lambda item: item[1], reverse = True)})\n",
    "\n",
    "plotDict(sortedcategoryToReviewCount, 10, \n",
    "         \"top10_business_by_reviews_categories.png\", \"Top-10 most reviewed business categories\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review Star Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starCounts = {}\n",
    "for stars, counts in rev_df['stars'].value_counts().iteritems():\n",
    "    starCounts[stars] = counts\n",
    "\n",
    "plt.bar(starCounts.keys(), starCounts.values(), color='b')\n",
    "plt.title(\"Count by Star Ratings\")\n",
    "plt.savefig(\"starCount.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review Length Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(rev_df['text'].str.len(), bins = 50, color = \"skyblue\")\n",
    "plt.xlabel(\"Review length\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Review length histogram\")\n",
    "plt.savefig(\"review_length_bins.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Review Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing Review data\\n\")\n",
    "print(rev_df.isna().sum())\n",
    "print(\"\\n\\nMissing Business data\\n\")\n",
    "print(biz_df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats_index = ['Mean', 'Median', '1Q', '3Q', 'Std', 'Min', 'Max']\n",
    "\n",
    "# biz_cols = ['review_count', 'stars']\n",
    "# rev_cols = ['cool', 'funny', 'stars', 'useful']\n",
    "# use_cols =  ['average_stars', 'compliment_cool', 'compliment_cute', 'compliment_funny', 'compliment_hot', 'compliment_list', 'compliment_more', 'compliment_note', 'compliment_photos', 'compliment_plain', 'compliment_profile', 'compliment_writer', 'cool', 'fans', 'funny', 'review_count', 'useful']\n",
    "\n",
    "# biz_stats = pd.DataFrame(index = stats_index, columns = biz_cols)\n",
    "# rev_stats = pd.DataFrame(index = stats_index, columns = rev_cols)\n",
    "# use_stats = pd.DataFrame(index = stats_index, columns = use_cols)\n",
    "\n",
    "# stats = [biz_stats, rev_stats, use_stats]\n",
    "# dfs = [biz_df, rev_df, use_df]\n",
    "\n",
    "# for i, stat in enumerate(stats):\n",
    "#     temp = dfs[i]\n",
    "#     for col in tqdm.tqdm_notebook(list(stat.columns.values)):\n",
    "#         print(col)\n",
    "#         stat.loc['Mean',col] = temp.loc[:,col].mean()\n",
    "#         # stat.loc['Mode',col] = temp.loc[:,col].mode(dropna=True)\n",
    "#         stat.loc['Median',col] = temp.loc[:,col].median()        \n",
    "#         stat.loc['1Q',col] = temp.loc[:,col].quantile(q=0.25)\n",
    "#         stat.loc['3Q',col] = temp.loc[:,col].quantile(q=0.75)\n",
    "#         stat.loc['Std',col] = temp.loc[:,col].std()\n",
    "#         stat.loc['Min',col] = temp.loc[:,col].min()\n",
    "#         stat.loc['Max',col] = temp.loc[:,col].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overview_cols = ['Number of Entries', 'Number of Incomplete', 'Number Attributes', 'Attributes']\n",
    "# overview_inds = ['business', 'checkin', 'photo', 'review', 'tip', 'user']\n",
    "# overview_dfs = [biz_df, ci_df, ph_df, rev_df, tip_df, use_df]\n",
    "\n",
    "# overview = pd.DataFrame(index = overview_inds, columns = overview_cols)\n",
    "\n",
    "# for i, df in enumerate(overview_dfs):\n",
    "#     overview.iloc[i,0] = df.shape[0]\n",
    "#     overview.iloc[i,1] = sum(df.isna().sum(axis=1)>0)\n",
    "#     overview.iloc[i,2] = df.shape[1]\n",
    "#     overview.iloc[i,3] = list(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59387"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# biz_df.loc[:,'is_restaurant'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15273"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum(biz_df.loc[biz_df.loc[:,'is_restaurant'],:].isna().sum(axis=1)>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rev_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6d4cac7a7687>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrev_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbiz_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'business_id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'is_restaurant'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'business_id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'rev_df' is not defined"
     ]
    }
   ],
   "source": [
    "# rev_df.join(biz_df[('business_id','is_restaurant')],on='business_id',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_path = r\"C:\\Users\\Willi\\Documents\\NYU\\2020 Spring\\Big Data Science\\Project\\Data_files\\Yelp Data Overview\\\\\"\n",
    "\n",
    "# overview_path = save_path + 'overview_stats.csv'\n",
    "# biz_path = save_path + 'business_stats.csv'\n",
    "# rev_path = save_path + 'review_stats.csv'\n",
    "# use_path = save_path + 'user_stats.csv'\n",
    "\n",
    "# stats_names = [biz_path, rev_path, use_path]\n",
    "\n",
    "# overview.to_csv(overview_path)\n",
    "\n",
    "# for i,stat in enumerate(stats):\n",
    "#     stat.to_csv(stats_names[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
